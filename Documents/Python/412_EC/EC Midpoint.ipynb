{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((20000, 126), (20000,))\n"
     ]
    }
   ],
   "source": [
    "# Load the data.\n",
    "letter_conv = lambda raw: float(int(raw, 16))\n",
    "\n",
    "\n",
    "filename = \"training.csv\"\n",
    "train_data = np.genfromtxt(filename, skip_header = 1, delimiter = ',', converters = {2: letter_conv},\n",
    "                            missing_values = '', filling_values = float(0.0), dtype = float).T\n",
    "filename = \"testing.csv\"\n",
    "test_data = np.genfromtxt(filename, skip_header = 1, delimiter = ',', converters = {2: letter_conv},\n",
    "                            missing_values = '', filling_values = float(0.0), dtype = float).T\n",
    "\n",
    "\n",
    "train_x = train_data[1:-1].T\n",
    "train_y = train_data[-1]\n",
    "test_x = test_data[1:].T\n",
    "test_ids = test_data[0]\n",
    "\n",
    "\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combined_training = np.concatenate((train_x, test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 20)\n"
     ]
    }
   ],
   "source": [
    "# # Preprocess the data\n",
    "# pca = PCA(20).fit(combined_training)\n",
    "# new_train_x = pca.transform(train_x)\n",
    "# new_test_x = pca.transform(test_x)\n",
    "# print(new_train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(new_train_x, train_y)\n",
    "\n",
    "results = gbc.predict(new_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({8.0: 4325, 6.0: 2205, 1.0: 1081, 2.0: 929, 7.0: 833, 5.0: 539, 4.0: 57, 3.0: 31})\n"
     ]
    }
   ],
   "source": [
    "f = open('results.csv', 'w')\n",
    "f.write('Id,Response\\n')\n",
    "for i in range(len(results)):\n",
    "\tline = (int(test_ids[i]), ',', int(results[i]), '\\n')\n",
    "\tfor i in line:\n",
    "\t\tf.write(str(i))\n",
    "f.close()\n",
    "\n",
    "tally = Counter(results)\n",
    "print(tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
